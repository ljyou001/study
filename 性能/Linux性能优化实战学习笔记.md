# Linux性能优化实战学习笔记

## [02 | 基础篇：到底应该怎么理解“平均负载”？](https://time.geekbang.org/column/article/69618)

### 平均负载

- 是指单位时间内，系统处于**可运行状态**和**不可中断状态**的平均进程数，也就是**平均活跃进程数**，它和 CPU 使用率并没有直接关系。

### 平均负载为多少时合理
- 首先你要知道系统有几个 CPU

```cmd
$ grep 'model name' /proc/cpuinfo | wc -l
```

- 当平均负载比 CPU 个数还大的时候，系统已经出现了过载

### uptime

```cmd
02:34:03              //当前时间
up 2 days, 20:14      //系统运行时间
1 user                //正在登录用户数
```

- 最后三个数，依次则是过去 1 分钟、5 分钟、15 分钟的平均负载（Load Average）

### 小白三板斧

#### 1. uptime 查看平均负载的变化情况

```cmd
# -d 参数表示高亮显示变化的区域
$ watch -d uptime
...,  load average: 1.00, 0.75, 0.39
```

#### 2. mpstat 查看 CPU 使用率的变化情况

```cmd
# -P ALL 表示监控所有CPU，后面数字5表示间隔5秒后输出一组数据
$ mpstat -P ALL 5
```

#### 3. pidstat 查找罪魁祸首

```cmd
# 间隔5秒后输出一组数据
$ pidstat -u 5 1
```

### 小结

- 平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。
 
 - 平均负载高有可能是 CPU 密集型进程导致的；
 - 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了；
 - 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。

## [03 | 基础篇：经常说的 CPU 上下文切换是什么意思？（上）](https://time.geekbang.org/column/article/69859)

- 过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成了系统性能大幅下降的一个元凶。

- CPU 寄存器和程序计数器（Program Counter，PC）也被叫做 CPU 上下文

- 根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景
  - 进程上下文切换
  - 线程上下文切换
  - 中断上下文切换

### 线程与进程最大的区别

- **线程是调度的基本单位，而进程则是资源拥有的基本单位**。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。
  
  - 当进程只有一个线程时，可以认为进程就等于线程。
  - 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。
  - 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。

### 中断上下文切换

- 为了快速响应硬件的事件，**中断处理会打断进程的正常调度和执行**，转而调用中断处理程序，响应设备事件。

- 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。

- 对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。

## [04 | 基础篇：经常说的 CPU 上下文切换是什么意思？（下）](https://time.geekbang.org/column/article/70077)

### vmstat 查询系统总体的上下文切换情况

- vmstat 是一个常用的系统性能分析工具，主要用来分析
  - 系统的内存使用情况
  - CPU 上下文切换和中断的次数

```cmd
# 每隔5秒输出1组数据
$ vmstat 5

# 每隔1秒输出2组数据
$ vmstat 1 2
```

需要特别关注的四列内容：

- cs（context switch）是每秒上下文切换的次数。
- in（interrupt）则是每秒中断的次数。
- r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
- b（Blocked）则是处于不可中断睡眠状态的进程数。

### pidstat -w 查看每个进程的详细情况

```cmd
# 每隔5秒输出1组数据
$ pidstat -w 5
```

重点关注两列

- cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数
- nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数

> - **自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换**。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。

> - **非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换**。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。


```cmd
# -w参数表示输出进程切换指标，而-u参数则表示输出CPU使用指标
$ pidstat -w -u 1
```

```cmd
# -wt 参数表示输出线程的上下文切换指标
$ pidstat -wt 1
```

### 观察中断的变化情况

```cmd
# -d 参数表示高亮显示变化的区域
$ watch -d cat /proc/interrupts
```

- **重调度中断**（RES），这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为**处理器间中断**（Inter-Processor Interrupts，IPI）。

### 每秒上下文切换多少次才算正常呢？

- **这个数值其实取决于系统本身的 CPU 性能。**如果系统的上下文切换次数比较稳定，那么从**数百**到**一万以内**，都应该算是正常的。

- 但当上下文切换次数**超过一万次**，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。

- 根据上下文切换的类型，分析原因：
 - 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；
 - 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈；
 - 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。

### 小结
- 可以借助 vmstat 、 pidstat 和 /proc/interrupts 等工具来排查性能问题。

## [05 | 基础篇：某个应用的CPU使用率居然达到100%，我该怎么办？](https://time.geekbang.org/column/article/70476)

- **性能分析工具给出的都是间隔一段时间的平均 CPU 使用率，所以要注意间隔时间的设置**，特别是用多个工具对比分析时，你一定要保证它们用的是相同的间隔时间。

### 查看 CPU 使用率

- top 显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况。
- ps 则只显示了每个进程的资源使用情况。

###  CPU 使用率相关的重要指标

- user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。
- nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。
- system（通常缩写为 sys），代表内核态 CPU 时间。
- idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）。
- iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间。
- irq（通常缩写为 hi），代表处理硬中断的 CPU 时间。
- softirq（通常缩写为 si），代表处理软中断的 CPU 时间。
- steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。
- guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。
- guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间。

### CPU 使用率过高怎么办？

- GDB（The GNU Project Debugger）， 功能强大的程序调试利器。
  - GDB 并不适合在性能分析的早期应用。
  - GDB 只适合用在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。

#### perf 适合在第一时间分析进程的 CPU 问题

- perf 是 Linux 2.6.31 以后内置的性能分析工具。
- 它以性能事件采样为基础
  - 不仅可以分析系统的各种事件和内核性能
  - 还可以用来分析指定应用程序的性能问题

##### 两种最常见方法

```cmd
$ perf top
```

输出结果中，第一行包含三个数据，分别是

- 采样数（Samples）
- 事件类型（event）
- 事件总数量（Event count）

**采样数需要我们特别注意**。如果采样数过少（比如只有十几个），那下面的排序和百分比就没什么实际参考价值了。

再往下看是一个表格式样的数据，每一行包含四列，分别是：

- 第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示。
- 第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。
- 第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间。
- 最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。

```cmd
perf record 和 perf report
```

perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record 则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。

```cmd
# 按Ctrl+C终止采样
$ perf record -g

# 展示类似于perf top的报告
$ perf report
```

在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。

## [06 | 案例篇：系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？](https://time.geekbang.org/column/article/70822)

### pstree 查找一个进程的父进程

```cmd
$ pstree | grep stress
```

### 分析 CPU 使用率的工具

- perf
- [execsnoop](https://github.com/brendangregg/perf-tools/blob/master/execsnoop)
 - 一个专为短时进程设计的工具。
 - 它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果。

### 小结

碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况。

- 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。
- 第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。

对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。

## [07 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）](https://time.geekbang.org/column/article/71064)

### TOP 命令

S 列（也就是 Status 列）表示进程的状态

- **R** 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。
- **D** 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。
- **Z** 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。
- **S** 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 
- **R** 状态。
- **I** 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。
- **T 或者 t** 也就是 Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。
- **X** 也就是 Dead 的缩写，表示进程已经消亡，所以你不会在 top 或者 ps 命令中看到它。

### dstat 性能工具

- 它吸收了 vmstat、iostat、ifstat 等几种工具的优点
- 可以同时观察系统的 CPU、磁盘 I/O、网络以及内存使用情况

## [08 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）](https://time.geekbang.org/column/article/71382)

### iowait 分析

- 推荐工具 dstat

```cmd
# 间隔1秒输出10组数据
$ dstat 1 10
```

根据进程号排查

```cmd
# -d 展示 I/O 统计数据，-p 指定进程号，间隔 1 秒输出 3 组数据
$ pidstat -d -p 4344 1 3
```

没有发现异常，去掉进程号，观察所有进程的 I/O 使用情况

```cmd
# 间隔 1 秒输出多组数据 (这里是 20 组)
$ pidstat -d 1 20
```

### strace 正是最常用的跟踪进程系统调用的工具

```cmd
# -p 参数指定 PID 号
$ strace -p 6082
```

检查进程状态是否正常

```cmd
$ ps aux | grep 6082
```

### 僵尸进程

pstree 查找父进程

```cmd
# -a 表示输出命令行选项
# p表PID
# s表示指定进程的父进程
$ pstree -aps 3084
```

### 小结

- iowait 高不一定代表 I/O 有性能瓶颈。
- 当系统中只有 I/O 类型的进程在运行时，iowait 也会很高，但实际上，磁盘的读写远没有达到性能瓶颈的程度。
- 碰到 iowait 升高时，需要先用 dstat、pidstat 等工具，确认是不是磁盘 I/O 的问题，然后再找是哪些进程导致了 I/O。

## [09 | 基础篇：怎么理解Linux软中断？](https://time.geekbang.org/column/article/71868)

### 查看软中断和内核线程

- /proc/softirqs 提供了软中断的运行情况
- /proc/interrupts 提供了硬中断的运行情况

查看 /proc/softirqs 文件的内容，你就可以看到各种类型软中断在不同 CPU 上的累积运行次数：

```cmd
$ cat /proc/softirqs
```

- **NET_RX** 表示网络接收中断 
- **NET_TX** 表示网络发送中断
- **TASKLET** 在不同 CPU 上的分布并不均匀。TASKLET 是最常用的软中断实现机制，每个 TASKLET 只运行一次就会结束 ，并且**只在调用它的函数所在的 CPU 上运行**
    - 缺点 
        - **由于只在一个 CPU 上运行导致的调度不均衡**
        - **因为不能在多个 CPU 上并行运行带来了性能限制**
- **TIMER** 定时中断
- **SCHED** 内核调度
- **RCU** RCU 锁


软中断实际上是以内核线程的方式运行的，每个 CPU 都对应一个软中断内核线程，这个软中断内核线程就叫做 ksoftirqd/CPU 编号。那要怎么查看这些线程的运行状况呢？

```cmd
ps aux | grep softirq
```

### 小结

- Linux 中的中断处理程序分为上半部和下半部
 - 上半部对应硬件中断，用来快速处理中断
 - 下半部对应软中断，用来异步处理上半部未完成的工作
- Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型，可以通过查看 /proc/softirqs 来观察软中断的运行情况

## 10 | 案例篇：系统的软中断CPU使用率升高，我该怎么办？

- sar 是一个系统活动报告工具，既可以实时查看系统的当前活动，又可以配置保存和报告历史统计数据。
- hping3 是一个可以构造 TCP/IP 协议数据包的工具，可以对系统进行安全审计、防火墙测试等。
- tcpdump 是一个常用的网络抓包工具，常用来分析各种网络问题。

### 观察中断次数的变化速率

```cmd
$ watch -d cat /proc/softirqs
```

### sar 用来查看系统的网络收发情况

- 不仅可以观察网络收发的吞吐量（BPS，每秒收发的字节数）
- 还可以观察网络收发的 PPS，即每秒收发的网络帧数

```cmd
# -n DEV 表示显示网络收发的报告，间隔1秒输出一组数据
$ sar -n DEV 1
```

sar 的输出界面，从左往右依次是：

- 第一列：表示报告的时间。
- 第二列：IFACE 表示网卡。
- 第三、四列：rxpck/s 和 txpck/s 分别表示每秒接收、发送的网络帧数，也就是 PPS（packet per second 每秒钟有多少数据包经过）。
- 第五、六列：rxkB/s 和 txkB/s 分别表示每秒接收、发送的千字节数，也就是 BPS（每秒钟有多少bit的数据经过）。

BPS * 1024 / PPS = 每个网络帧的字节
如果这个值很小（不足100），就说明是遇到了小包问题

通过 tcpdump 查找小包来源

```cmd
# -i eth0 只抓取eth0网卡，-n不解析协议名和主机名
# tcp port 80表示只抓取tcp协议并且端口号为80的网络帧
$ tcpdump -i eth0 -n tcp port 80
```

### 小结

- 软中断 CPU 使用率（softirq）升高是一种很常见的性能问题。
- 实际生产中，我们遇到的性能瓶颈大多是网络收发类型的软中断，特别是网络接收的软中断。
- 碰到这类问题时，你可以借用 sar、tcpdump 等工具，做进一步分析。

## [11 | 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？](https://time.geekbang.org/column/article/72685)

直接看原文，套路满满，尤其是最后一个图

## [12 | 套路篇：CPU 性能优化的几个思路](https://time.geekbang.org/column/article/73151)

### 怎么评估性能优化的效果？
不要局限在单一维度的指标上，你至少要从应用程序和系统资源这两个维度

- 应用程序的维度，我们可以用**吞吐量和请求延迟**来评估应用程序的性能。
- 系统资源的维度，我们可以用 **CPU 使用率**来评估系统的 CPU 使用情况。

**并不是所有的性能问题都值得优化**
 
 - 找出最重要的、可以最大程度提升性能的问题，从它开始优化。

**性能优化并非没有成本**

### 应用程序优化

- 异步处理
- 善用缓存

### 系统优化

- **CPU 绑定**：把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题。
- **CPU 独占**：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU。
- **优先级调整**：使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。优先级的数值含义前面我们提到过，忘了的话及时复习一下。在这里，适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理。为进程设置资源限制：使用 Linux cgroups 来设置进程的 CPU 使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源。
- **NUMA（Non-Uniform Memory Access）优化**：支持 NUMA 的处理器会被划分为多个 node，每个 node 都有自己的本地内存空间。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存。
- **中断负载均衡**：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的 CPU。开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均衡到多个 CPU 上。

## [14 | 答疑（二）：如何用perf工具分析Java程序？](https://time.geekbang.org/column/article/73738)

- perf 这种动态追踪工具，会给系统带来一定的性能损失。
- vmstat、pidstat 这些直接读取proc 文件系统来获取指标的工具，不会带来性能损失。

### 性能优化书籍和参考资料推荐

**Brendan Gregg 性能优化大师**

- 《Systems Performance: Enterprise and the Cloud》。这本书也出了中文版，名字是《性能之巅：洞悉系统、企业与云计算》。这本书里的性能分析思路以及很多的性能工具，到今天依然适用。
- [Brendan Gregg 个人网站](http://www.brendangregg.com/)
- 特别是 [Linux Performance](http://www.brendangregg.com/linuxperf.html) 这个页面，包含了很多 Linux 性能优化的资料
    - Linux 性能工具图谱
    - 性能分析参考资料
    - 性能优化的演讲视频

## [15 | 基础篇：Linux内存是怎么工作的？](https://time.geekbang.org/column/article/74272)

- 通过减少进程的上下文切换，减少 TLB 的刷新次数，就可以提高 TLB 缓存的使用率，进而提高 CPU 的内存访问性能
- 页的大小只有 4 KB ，导致的另一个问题就是，整个页表会变得非常大。比方说，仅 32 位系统就需要 100 多万个页表项（4GB/4KB），才可以实现整个地址空间的映射
- 为了**解决页表项过多的问题**，Linux 提供了两种机制，也就是**多级页表**和**大页**（HugePage）。
- **大页**：常见的大小有 2MB 和 1GB
- Swap 会导致严重的内存性能问题

管理员可以通过 /proc 文件系统，手动设置进程的 oom_adj ，从而调整进程的 oom_score。oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；数值越小，表示进程越不容易被 OOM 杀死，其中 -17 表示禁止 OOM。

```cmd
echo -16 > /proc/$(pidof sshd)/oom_adj
```

### 如何查看内存使用情况

**free** 命令显示整个系统的内存使用情况

```cmd
$ free
```

- 第一列，total 是总内存大小；
- 第二列，used 是已使用内存的大小，包含了共享内存；
- 第三列，free 是未使用内存的大小；
- 第四列，shared 是共享内存的大小；
- 第五列，buff/cache 是缓存和缓冲区的大小；
- 最后一列，available 是新进程可用内存的大小。
    - available 不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。

查看进程的内存使用情况，可以用 **top** 或者 **ps** 等工具

```cmd
# 按下M切换到内存排序
$ top
```

跟内存相关的几列数据，VIRT、RES、SHR、%MEM

- **VIRT** 是进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。
    - 虚拟内存通常并不会全部分配物理内存。从上面的输出，你可以发现每个进程的虚拟内存都比常驻内存大得多。
- **RES** 是常驻内存的大小，也就是进程实际使用的物理内存大小，但不包括 Swap 和共享内存。
- **SHR** 是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等。
    - 共享内存 SHR 并不一定是共享的，比方说，程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。
    - 所以在计算多个进程的内存使用时，不要把所有进程的 SHR 直接相加得出结果。
- **%MEM** 是进程使用物理内存占系统总内存的百分比。

### 小结

- 对普通进程来说，它能看到的其实是内核提供的虚拟内存，这些虚拟内存还需要通过页表，由系统映射为物理内存。
- 当进程通过 malloc() 申请内存后，内存并不会立即分配，而是在首次访问时，才通过缺页异常陷入内核中分配内存。

## [16 | 基础篇：怎么理解内存中的Buffer和Cache？](https://time.geekbang.org/column/article/74633)

清理系统缓存

```cmd
# 清理文件页、目录项、Inodes等各种缓存
$ echo 3 > /proc/sys/vm/drop_caches
```

**Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。**

## [17 | 案例篇：如何利用系统缓存优化程序的运行效率？](https://time.geekbang.org/column/article/75242)

### 缓存命中率

- 命中率越高，表示使用缓存带来的收益越高，应用程序的性能也就越好。

#### cachestat 和 cachetop ，是查看系统缓存命中情况的工具

- cachestat 提供了整个操作系统缓存的读写命中情况。
- cachetop 提供了每个进程的缓存命中情况。

使用 cachestat 和 cachetop 前，我们首先要安装 bcc 软件包

```cmd
$ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD
$echo "deb https://repo.iovisor.org/apt/xenial xenial main" | sudo tee /etc/apt/sources.list.d/iovisor.list
$ apt-get update
$ apt-get install -y bcc-tools libbcc-examples linux-headers-$(uname -r)
```

操作完这些步骤，bcc 提供的所有工具就都安装到 /usr/share/bcc/tools 这个目录中了。不过这里提醒你，bcc 软件包默认不会把这些工具配置到系统的 PATH 路径中，所以你得自己手动配置：

```cmd
$ export PATH=$PATH:/usr/share/bcc/tools
```

##### 没有成功！

[使用 snap 安装 bcc](https://snapcraft.io/install/bcc/ubuntu)

安装后进入 /snap/bin

```cmd
$ cd /snap/bin

# 运行时例如
$ ./bcc.filetop -C
```

```cmd
# 查看Linux 内核版本 
cat /proc/version
```

## [18 | 案例篇：内存泄漏了，我该如何定位和处理？](https://time.geekbang.org/column/article/75670)

- 栈内存由系统自动分配和管理
- 堆内存由应用程序自己来分配和管理

### memleak 专门用来检测内存泄漏的工具
- memleak 是 bcc 软件包中的一个工具

## [19 | 案例篇：为什么系统的Swap变高了（上）](https://time.geekbang.org/column/article/75797)

### kswapd0
- 专门的内核线程用来定期回收内存
- kswapd0 定义了三个内存阈值（watermark，也称为水位
    - 页最小阈值（pages_min）
    - 页低阈值（pages_low）
    - 页高阈值（pages_high）
    - 剩余内存，则使用 pages_free 表示。

### numactl 命令
- 来查看处理器在 Node 的分布情况
- 以及每个 Node 的内存使用情况

```cmd
$ numactl --hardware
```

## [20 | 案例篇：为什么系统的Swap变高了？（下）](https://time.geekbang.org/column/article/75973)

Linux 本身支持两种类型的 Swap

- Swap 分区和 
- Swap 文件

降低 Swap 的使用，可以提高系统的整体性能

## [21 | 套路篇：如何“快准狠”找到系统内存的问题？](https://time.geekbang.org/column/article/76460)

套路满满，详见文章配图

### 内存性能指标（详见文中插图）

- 系统
- 进程
- SWAP

### 内存性能工具
- 通过 proc 文件系统，找到了内存指标的来源
- free 查看系统的整体内存和 Swap 使用情况
- top 或 ps，查看进程的内存使用情况
- vmstat 除了可以动态查看内存变化，还可以区分缓存和缓冲区、Swap 换入和换出的内存大小
- cachestat 查看整个系统缓存的读写命中情况
- cachetop 观察每个进程缓存的读写命中情况
- memleak 找到内存泄漏的可疑位置
- sar 发现了缓冲区和 Swap 升高的问题

**为了迅速定位内存问题，通常会先运行几个覆盖面比较大的性能工具，比如 free、top、vmstat、pidstat 等。**

### 常见的优化思路
- 最好禁止 Swap。如果必须开启 Swap，降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。
- 减少内存的动态分配。比如，可以使用内存池、大页（HugePage）等。
- 尽量使用缓存和缓冲区来访问数据。比如，可以使用堆栈明确声明内存空间，来存储需要缓存的数据；或者用 Redis 这类的外部缓存组件，优化数据的访问。
- 使用 cgroups 等方式限制进程的内存使用情况。这样，可以确保系统内存不会被异常进程耗尽。
- 通过 /proc/pid/oom_adj ，调整核心应用的 oom_score。这样，可以保证即使内存紧张，核心应用也不会被 OOM 杀死。

## [23 | 基础篇：Linux 文件系统是怎么工作的？](https://time.geekbang.org/column/article/76876)

- Linux 中一切皆文件。不仅普通的文件和目录，就连块设备、套接字、管道等，也都要通过统一的文件系统来管理。
- 一个文件可以有多个别名

### 虚拟文件系统

- 为了支持各种不同的文件系统，Linux 内核在用户进程和文件系统的中间，又引入了一个抽象层，也就是虚拟文件系统 VFS（Virtual File System）。

### 文件读写方式的各种差异，导致 I/O 的分类多种多样

- 根据**是否利用标准库缓存**，可以把文件 I/O 分为缓冲 I/O 与非缓冲 I/O。
    - 缓冲 I/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调度访问文件。
    - 非缓冲 I/O，是指直接通过系统调用来访问文件，不再经过标准库缓存。

- 根据**是否利用操作系统的页缓存**，可以把文件 I/O 分为直接 I/O 与非直接 I/O
    - 直接 I/O，是指跳过操作系统的页缓存，直接跟文件系统交互来访问文件
    - 非直接 I/O 正好相反，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘
    - 直接 I/O、非直接 I/O，本质上还是和文件系统交互。如果是在数据库等场景中，你还会看到，跳过文件系统读写磁盘的情况，也就是我们通常所说的**裸 I/O**

- 根据应用程序**是否阻塞自身运行**，可以把文件 I/O 分为阻塞 I/O 和非阻塞 I/O
    - 阻塞 I/O，是指应用程序执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，自然就不能执行其他任务
    - 非阻塞 I/O，是指应用程序执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过轮询或者事件通知的形式，获取调用的结果
   
 - 根据**是否等待响应结果**，可以把文件 I/O 分为同步和异步 I/O
    - 同步 I/O，是指应用程序执行 I/O 操作后，要一直等到整个 I/O 完成后，才能获得 I/O 响应
    - 异步 I/O，是指应用程序执行 I/O 操作后，不用等待完成和完成后的响应，而是继续执行就可以。等到这次 I/O 完成后，响应会用事件通知的方式，告诉应用程序

### 性能观测

```
$ df -h /dev/sda1

$ df -i /dev/sda1
```

## [24 | 基础篇：Linux 磁盘I/O是怎么工作的（上）](https://time.geekbang.org/column/article/77010)

- 连续 I/O 还可以通过预读的方式，来减少 I/O 请求的次数，这也是其性能优异的一个原因

Linux 内核支持四种 I/O 调度算法

- NONE
- NOOP : 实际上是一个先入先出的队列，只做一些最基本的请求合并，常用于 SSD 磁盘
- CFQ
- DeadLine : 分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量，并确保达到最终期限（deadline）的请求被优先处理。DeadLine 调度算法，多用在 I/O 压力比较重的场景，比如数据库等。

### I/O 栈

由上到下分为三个层次，分别是文件系统层、通用块层和设备层

- **文件系统层**，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据。
- **通用块层**，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。
- **设备层**，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。

存储系统的 I/O ，通常是整个系统中最慢的一环。所以， Linux 通过多种缓存机制来优化 I/O 效率。

## [25 | 基础篇：Linux 磁盘I/O是怎么工作的（下）](https://time.geekbang.org/column/article/77511)

### 磁盘性能指标

五个常见指标

- 使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。
    - 使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是 100% 的时候，磁盘依然有可能接受新的 I/O 请求
- 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。
- IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。
- 吞吐量，是指每秒的 I/O 请求大小。
- 响应时间，是指 I/O 请求从发出到收到响应的间隔时间。

不要孤立地去比较某一指标，而要结合读写比例、I/O 类型（随机还是连续）以及 I/O 的大小，综合来分析

- 在数据库、大量小文件等这类随机读写比较多的场景中，IOPS 更能反映系统的整体性能；
- 而在多媒体等顺序读写较多的场景中，吞吐量才更能反映系统的整体性能。

性能测试工具 **fio** ，来测试磁盘的 IOPS、吞吐量以及响应时间等核心指标


```cmd
# -d -x表示显示所有磁盘I/O的指标
$ iostat -d -x 1
```
输出结果说明见原文插图

- **%util** ，就是我们前面提到的磁盘 I/O 使用率；
- **r/s+ w/s** ，就是 IOPS；
- **rkB/s+wkB/s** ，就是吞吐量；
- **r_await+w_await** ，就是响应时间。

观察进程的 I/O 情况，你还可以使用 pidstat 和 iotop 这两个工具。

```cmd
$ pidstat -d 1
```

iotop 可以按照 I/O 大小对进程排序，然后找到 I/O 较大的那些进程

```cmd
$ iotop
```

## [26 | 案例篇：如何找出狂打日志的“内鬼”？](https://time.geekbang.org/column/article/77885)

**lsof** 命令，看看进程都打开了哪些文件

```cmd
lsof -p 18940
```

## [27 | 案例篇：为什么我的磁盘I/O延迟很高？](https://time.geekbang.org/column/article/78409)

**filetop** 它是 bcc 软件包的一部分，基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。

```cmd
$ /snap/bin/bcc.filetop -C
```

**opensnoop** 它同属于 bcc 软件包，可以动态跟踪内核中的 open 系统调用

```cmd
$ /snap/bin/bcc.opensnoop
```

## [30 | 套路篇：如何迅速分析出系统I/O的瓶颈在哪里？](https://time.geekbang.org/column/article/79001)
套路直接看原文

## [31 | 套路篇：磁盘 I/O 性能优化的几个思路](https://time.geekbang.org/column/article/79368)

### I/O 基准测试

[fio](https://github.com/axboe/fio) （Flexible I/O Tester）

- 最常用的文件系统和磁盘 I/O 性能基准测试工具
- 提供了大量的可定制化选项，可以用来测试，裸盘或者文件系统在各种场景下的 I/O 性能，包括了不同块大小、不同 I/O 引擎以及是否使用缓存等场景。

通过 blktrace+fio 的组合使用，可以得到应用程序 I/O 模式的基准测试报告

## [32 | 答疑（四）：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系](https://time.geekbang.org/column/article/79734)

阻塞 / 非阻塞和同步 / 异步，其实就是两个不同角度的 I/O 划分方式。它们描述的对象也不同

- 阻塞 / 非阻塞针对的是 I/O **调用者**（即应用程序）
- 同步 / 异步针对的是 I/O **执行者**（即系统）


